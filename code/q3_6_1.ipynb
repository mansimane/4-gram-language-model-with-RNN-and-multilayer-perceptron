{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((86402, 3), (86402, 8000))\n"
     ]
    }
   ],
   "source": [
    "#Data Preprocessing\n",
    "from prepare_text_data import *\n",
    "from config_3_2 import *\n",
    "from ngram_functions import *\n",
    "param = initialize_weights(hyper_para)\n",
    "x_train, y_train, x_val, y_val = prepare_text_data(param)\n",
    "print(x_train.shape, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Importing Library\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Recurrent, LSTM, Dense, Embedding\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from generic_functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "(86402, 3) (86402, 8000)\n"
     ]
    }
   ],
   "source": [
    "y_train = np.load('obj/y_train.pkl.npy')\n",
    "print(\"a\")\n",
    "y_val = np.load('obj/y_val.npy')\n",
    "x_val = np.load('obj/x_val.npy')\n",
    "x_train = np.load('obj/x_train.npy')\n",
    "\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 86402 samples, validate on 10360 samples\n",
      "Epoch 1/10\n",
      "86402/86402 [==============================] - 30s - loss: 8.6658 - val_loss: 8.2242\n",
      "Epoch 2/10\n",
      "86402/86402 [==============================] - 30s - loss: 7.6674 - val_loss: 6.8667\n",
      "Epoch 3/10\n",
      "86402/86402 [==============================] - 30s - loss: 6.9227 - val_loss: 6.4582\n",
      "Epoch 4/10\n",
      "86402/86402 [==============================] - 30s - loss: 6.6868 - val_loss: 6.3211\n",
      "Epoch 5/10\n",
      "84480/86402 [============================>.] - ETA: 0s - loss: 6.5972"
     ]
    }
   ],
   "source": [
    "\n",
    "#Build the model\n",
    "\n",
    "model = Sequential()\n",
    "no_of_words = 8000\n",
    "word_embedding_size = 16\n",
    "RNN_length = 32\n",
    "batch_size = 16\n",
    "epochs = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "model.add(Embedding(no_of_words, word_embedding_size, input_length=3))\n",
    "model.add(LSTM(RNN_length,activation='tanh', return_sequences = False))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(no_of_words, activation='softmax'))\n",
    "\n",
    "\n",
    "#input_array = np.random.randint(1000, size=(32, 10))\n",
    "sgd = optimizers.SGD(lr=learning_rate)\n",
    "model.compile(optimizer = sgd, loss = 'categorical_crossentropy')\n",
    "model.fit(x_train, y_train, validation_data = (x_val, y_val), batch_size = batch_size, epochs = epochs)\n",
    "\n",
    "output_array = model.predict(input_array)\n",
    "assert output_array.shape == (32, 10, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
