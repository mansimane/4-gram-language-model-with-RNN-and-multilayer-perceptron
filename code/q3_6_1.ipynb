{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importing Library\n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Recurrent, LSTM, Dense, Embedding\n",
    "from prepare_text_data import *\n",
    "from config_3_2 import *\n",
    "from ngram_functions import *\n",
    " \n",
    "from keras import optimizers \n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((86402, 3), (86402, 8000))\n"
     ]
    }
   ],
   "source": [
    "#Data Preprocessing\n",
    "param = initialize_weights(hyper_para)\n",
    "x_train, y_train, x_val, y_val = prepare_text_data(param)\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 86402 samples, validate on 10360 samples\n",
      "Epoch 1/10\n",
      "86402/86402 [==============================] - 277s - loss: 6.3583 - val_loss: 5.7902\n",
      "Epoch 2/10\n",
      "86402/86402 [==============================] - 273s - loss: 6.0329 - val_loss: 5.6307\n",
      "Epoch 3/10\n",
      "86402/86402 [==============================] - 242s - loss: 5.9391 - val_loss: 5.5597:\n",
      "Epoch 4/10\n",
      "86402/86402 [==============================] - 217s - loss: 5.9650 - val_loss: 5.7592\n",
      "Epoch 5/10\n",
      "84464/86402 [============================>.] - ETA: 6s - loss: 6.7249"
     ]
    }
   ],
   "source": [
    "#Build the model\n",
    "\n",
    "model = Sequential()\n",
    "no_of_words = 8000\n",
    "word_embedding_size = 16\n",
    "RNN_length = 32\n",
    "batch_size = 16\n",
    "epochs = 10\n",
    "\n",
    "model.add(Embedding(no_of_words, word_embedding_size, input_length=3))\n",
    "model.add(LSTM(RNN_length,activation='tanh', return_sequences = False))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(no_of_words, activation='softmax'))\n",
    "\n",
    "\n",
    "#input_array = np.random.randint(1000, size=(32, 10))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy')\n",
    "model.fit(x_train, y_train, validation_data = (x_val, y_val), batch_size = batch_size, epochs = epochs)\n",
    "\n",
    "output_array = model.predict(input_array)\n",
    "assert output_array.shape == (32, 10, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
